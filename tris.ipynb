{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tris",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "0kAlj012JWPN",
        "colab_type": "code",
        "outputId": "48fea873-a151-4c66-f840-7c3534c22f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data\"\n",
        "ds = pd.read_csv(url)\n",
        "\n",
        "ds.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>x.1</th>\n",
              "      <th>x.2</th>\n",
              "      <th>x.3</th>\n",
              "      <th>o</th>\n",
              "      <th>o.1</th>\n",
              "      <th>x.4</th>\n",
              "      <th>o.2</th>\n",
              "      <th>o.3</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x x.1 x.2 x.3  o o.1 x.4 o.2 o.3  positive\n",
              "0  x   x   x   x  o   o   o   x   o  positive\n",
              "1  x   x   x   x  o   o   o   o   x  positive\n",
              "2  x   x   x   x  o   o   o   b   b  positive\n",
              "3  x   x   x   x  o   o   b   o   b  positive\n",
              "4  x   x   x   x  o   o   b   b   o  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "Ew6exY4RJtiu",
        "colab_type": "code",
        "outputId": "df6597c7-0d21-469b-e472-829f6189b107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "x = ds.iloc[:, :9].values\n",
        "print(x[0:10])\n",
        "y = ds['positive'].values\n",
        "print(y[0:10])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['x' 'x' 'x' 'x' 'o' 'o' 'o' 'x' 'o']\n",
            " ['x' 'x' 'x' 'x' 'o' 'o' 'o' 'o' 'x']\n",
            " ['x' 'x' 'x' 'x' 'o' 'o' 'o' 'b' 'b']\n",
            " ['x' 'x' 'x' 'x' 'o' 'o' 'b' 'o' 'b']\n",
            " ['x' 'x' 'x' 'x' 'o' 'o' 'b' 'b' 'o']\n",
            " ['x' 'x' 'x' 'x' 'o' 'b' 'o' 'o' 'b']\n",
            " ['x' 'x' 'x' 'x' 'o' 'b' 'o' 'b' 'o']\n",
            " ['x' 'x' 'x' 'x' 'o' 'b' 'b' 'o' 'o']\n",
            " ['x' 'x' 'x' 'x' 'b' 'o' 'o' 'o' 'b']\n",
            " ['x' 'x' 'x' 'x' 'b' 'o' 'o' 'b' 'o']]\n",
            "['positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
            " 'positive' 'positive' 'positive' 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6BFm23RFM3rz",
        "colab_type": "code",
        "outputId": "8cdbc179-c6ca-48fc-cd28-b457b88551d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "for _ in range(9):\n",
        "  x[:,_] = le.fit_transform(x[:,_])\n",
        "print(x) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 2 2 ... 1 2 1]\n",
            " [2 2 2 ... 1 1 2]\n",
            " [2 2 2 ... 1 0 0]\n",
            " ...\n",
            " [1 2 1 ... 2 1 2]\n",
            " [1 2 1 ... 2 1 2]\n",
            " [1 1 2 ... 1 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cx5NROpKPsGi",
        "colab_type": "code",
        "outputId": "fd49671a-4159-42ef-f796-c6ec301476fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "cell_type": "code",
      "source": [
        "y = le.fit_transform(y)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ymPh8MM-RjD3",
        "colab_type": "code",
        "outputId": "56ced154-0d13-41c4-8216-e10315e1ad87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "one_hot = preprocessing.OneHotEncoder(categorical_features = [0,1,2,3,4,5,6,7,8])\n",
        "x = one_hot.fit_transform(x).toarray()\n",
        "x = np.delete(x, [0,3,6,9,12,15,18,21,24], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "i1l62u7mTG7v",
        "colab_type": "code",
        "outputId": "304fc653-4053-4675-c578-8433863f2de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3550
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(9, activation='relu', input_dim=18))\n",
        "model.add(Dense(9, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "765/765 [==============================] - 1s 729us/step - loss: 0.6507 - acc: 0.6523\n",
            "Epoch 2/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.6220 - acc: 0.6575\n",
            "Epoch 3/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.6003 - acc: 0.6641\n",
            "Epoch 4/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.5803 - acc: 0.6693\n",
            "Epoch 5/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.5606 - acc: 0.6902\n",
            "Epoch 6/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.5422 - acc: 0.7346\n",
            "Epoch 7/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.5249 - acc: 0.7438\n",
            "Epoch 8/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.5092 - acc: 0.7621\n",
            "Epoch 9/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.4907 - acc: 0.7660\n",
            "Epoch 10/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.4730 - acc: 0.7752\n",
            "Epoch 11/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.4548 - acc: 0.7712\n",
            "Epoch 12/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.4365 - acc: 0.7817\n",
            "Epoch 13/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.4132 - acc: 0.7974\n",
            "Epoch 14/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.3906 - acc: 0.8196\n",
            "Epoch 15/100\n",
            "765/765 [==============================] - 0s 104us/step - loss: 0.3626 - acc: 0.8353\n",
            "Epoch 16/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.3238 - acc: 0.8732\n",
            "Epoch 17/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.2862 - acc: 0.9190\n",
            "Epoch 18/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.2469 - acc: 0.9516\n",
            "Epoch 19/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.2147 - acc: 0.9725\n",
            "Epoch 20/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.1816 - acc: 0.9778\n",
            "Epoch 21/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.1538 - acc: 0.9843\n",
            "Epoch 22/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.1332 - acc: 0.9843\n",
            "Epoch 23/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.1215 - acc: 0.9843\n",
            "Epoch 24/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.1069 - acc: 0.9843\n",
            "Epoch 25/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0971 - acc: 0.9869\n",
            "Epoch 26/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0878 - acc: 0.9869\n",
            "Epoch 27/100\n",
            "765/765 [==============================] - 0s 115us/step - loss: 0.0813 - acc: 0.9869\n",
            "Epoch 28/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0753 - acc: 0.9856\n",
            "Epoch 29/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0715 - acc: 0.9856\n",
            "Epoch 30/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0674 - acc: 0.9856\n",
            "Epoch 31/100\n",
            "765/765 [==============================] - 0s 102us/step - loss: 0.0625 - acc: 0.9856\n",
            "Epoch 32/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0619 - acc: 0.9856\n",
            "Epoch 33/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0577 - acc: 0.9869\n",
            "Epoch 34/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0578 - acc: 0.9869\n",
            "Epoch 35/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0564 - acc: 0.9882\n",
            "Epoch 36/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0546 - acc: 0.9869\n",
            "Epoch 37/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0571 - acc: 0.9856\n",
            "Epoch 38/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0504 - acc: 0.9882\n",
            "Epoch 39/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0504 - acc: 0.9856\n",
            "Epoch 40/100\n",
            "765/765 [==============================] - 0s 104us/step - loss: 0.0477 - acc: 0.9856\n",
            "Epoch 41/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0486 - acc: 0.9882\n",
            "Epoch 42/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0461 - acc: 0.9869\n",
            "Epoch 43/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0463 - acc: 0.9869\n",
            "Epoch 44/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0447 - acc: 0.9869\n",
            "Epoch 45/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0478 - acc: 0.9869\n",
            "Epoch 46/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0462 - acc: 0.9869\n",
            "Epoch 47/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0453 - acc: 0.9882\n",
            "Epoch 48/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0408 - acc: 0.9869\n",
            "Epoch 49/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0431 - acc: 0.9882\n",
            "Epoch 50/100\n",
            "765/765 [==============================] - 0s 115us/step - loss: 0.0455 - acc: 0.9869\n",
            "Epoch 51/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0409 - acc: 0.9869\n",
            "Epoch 52/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0398 - acc: 0.9882\n",
            "Epoch 53/100\n",
            "765/765 [==============================] - 0s 113us/step - loss: 0.0409 - acc: 0.9869\n",
            "Epoch 54/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0389 - acc: 0.9895\n",
            "Epoch 55/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0366 - acc: 0.9908\n",
            "Epoch 56/100\n",
            "765/765 [==============================] - 0s 105us/step - loss: 0.0396 - acc: 0.9895\n",
            "Epoch 57/100\n",
            "765/765 [==============================] - 0s 105us/step - loss: 0.0366 - acc: 0.9908\n",
            "Epoch 58/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0393 - acc: 0.9895\n",
            "Epoch 59/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0351 - acc: 0.9895\n",
            "Epoch 60/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0338 - acc: 0.9908\n",
            "Epoch 61/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0368 - acc: 0.9882\n",
            "Epoch 62/100\n",
            "765/765 [==============================] - 0s 120us/step - loss: 0.0380 - acc: 0.9908\n",
            "Epoch 63/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0363 - acc: 0.9895\n",
            "Epoch 64/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0368 - acc: 0.9882\n",
            "Epoch 65/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0403 - acc: 0.9869\n",
            "Epoch 66/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0346 - acc: 0.9856\n",
            "Epoch 67/100\n",
            "765/765 [==============================] - 0s 113us/step - loss: 0.0361 - acc: 0.9922\n",
            "Epoch 68/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0351 - acc: 0.9882\n",
            "Epoch 69/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0344 - acc: 0.9895\n",
            "Epoch 70/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0312 - acc: 0.9908\n",
            "Epoch 71/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0352 - acc: 0.9882\n",
            "Epoch 72/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0318 - acc: 0.9908\n",
            "Epoch 73/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0333 - acc: 0.9895\n",
            "Epoch 74/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0320 - acc: 0.9869\n",
            "Epoch 75/100\n",
            "765/765 [==============================] - 0s 113us/step - loss: 0.0349 - acc: 0.9922\n",
            "Epoch 76/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0298 - acc: 0.9922\n",
            "Epoch 77/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0357 - acc: 0.9882\n",
            "Epoch 78/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0327 - acc: 0.9882\n",
            "Epoch 79/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0297 - acc: 0.9895\n",
            "Epoch 80/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0302 - acc: 0.9882\n",
            "Epoch 81/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0280 - acc: 0.9895\n",
            "Epoch 82/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0286 - acc: 0.9895\n",
            "Epoch 83/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0311 - acc: 0.9882\n",
            "Epoch 84/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0288 - acc: 0.9922\n",
            "Epoch 85/100\n",
            "765/765 [==============================] - 0s 106us/step - loss: 0.0268 - acc: 0.9922\n",
            "Epoch 86/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0375 - acc: 0.9882\n",
            "Epoch 87/100\n",
            "765/765 [==============================] - 0s 115us/step - loss: 0.0308 - acc: 0.9895\n",
            "Epoch 88/100\n",
            "765/765 [==============================] - 0s 108us/step - loss: 0.0274 - acc: 0.9895\n",
            "Epoch 89/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0287 - acc: 0.9922\n",
            "Epoch 90/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0280 - acc: 0.9908\n",
            "Epoch 91/100\n",
            "765/765 [==============================] - 0s 112us/step - loss: 0.0271 - acc: 0.9895\n",
            "Epoch 92/100\n",
            "765/765 [==============================] - 0s 104us/step - loss: 0.0269 - acc: 0.9908\n",
            "Epoch 93/100\n",
            "765/765 [==============================] - 0s 115us/step - loss: 0.0286 - acc: 0.9882\n",
            "Epoch 94/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0289 - acc: 0.9869\n",
            "Epoch 95/100\n",
            "765/765 [==============================] - 0s 111us/step - loss: 0.0305 - acc: 0.9895\n",
            "Epoch 96/100\n",
            "765/765 [==============================] - 0s 110us/step - loss: 0.0266 - acc: 0.9895\n",
            "Epoch 97/100\n",
            "765/765 [==============================] - 0s 107us/step - loss: 0.0288 - acc: 0.9882\n",
            "Epoch 98/100\n",
            "765/765 [==============================] - 0s 105us/step - loss: 0.0314 - acc: 0.9856\n",
            "Epoch 99/100\n",
            "765/765 [==============================] - 0s 113us/step - loss: 0.0271 - acc: 0.9922\n",
            "Epoch 100/100\n",
            "765/765 [==============================] - 0s 109us/step - loss: 0.0269 - acc: 0.9922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23a1629b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "jIi7s3Lwajco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('tictac.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Tgu5wsOdSWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('tictac.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRtkTDPvdXxP",
        "colab_type": "code",
        "outputId": "796d0d33-92cb-4f2e-d4af-a0fcefad50f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3391
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.53392553e-04]\n",
            " [9.84738588e-01]\n",
            " [9.98849034e-01]\n",
            " [1.20997429e-05]\n",
            " [1.27041340e-03]\n",
            " [9.96400356e-01]\n",
            " [9.94406343e-01]\n",
            " [9.83775616e-01]\n",
            " [8.18408370e-01]\n",
            " [1.97546482e-02]\n",
            " [9.67717767e-01]\n",
            " [9.99934733e-01]\n",
            " [9.99927938e-01]\n",
            " [7.30706513e-01]\n",
            " [9.87885058e-01]\n",
            " [9.96032417e-01]\n",
            " [9.99711752e-01]\n",
            " [9.86914515e-01]\n",
            " [4.27365303e-05]\n",
            " [5.77145815e-03]\n",
            " [1.74871087e-03]\n",
            " [9.46375072e-01]\n",
            " [5.92368841e-03]\n",
            " [9.92180347e-01]\n",
            " [1.59269571e-03]\n",
            " [9.92389679e-01]\n",
            " [9.60094571e-01]\n",
            " [9.99284148e-01]\n",
            " [8.97907197e-01]\n",
            " [9.99097645e-01]\n",
            " [9.99969661e-01]\n",
            " [9.85187888e-01]\n",
            " [9.99635816e-01]\n",
            " [9.99280453e-01]\n",
            " [1.26430392e-03]\n",
            " [5.55068254e-04]\n",
            " [9.92208719e-01]\n",
            " [9.99538898e-01]\n",
            " [9.99982119e-01]\n",
            " [2.27987766e-05]\n",
            " [9.99943495e-01]\n",
            " [9.99232888e-01]\n",
            " [4.77522612e-04]\n",
            " [7.45683908e-04]\n",
            " [9.90266204e-01]\n",
            " [8.28185380e-02]\n",
            " [9.98338580e-01]\n",
            " [9.99924779e-01]\n",
            " [9.06586647e-05]\n",
            " [3.50668132e-02]\n",
            " [1.07077062e-02]\n",
            " [4.69982624e-04]\n",
            " [9.91111517e-01]\n",
            " [9.90970254e-01]\n",
            " [9.89084542e-01]\n",
            " [9.99730945e-01]\n",
            " [9.97636974e-01]\n",
            " [2.66134739e-04]\n",
            " [2.92867422e-03]\n",
            " [9.99696732e-01]\n",
            " [9.96623635e-01]\n",
            " [9.96573269e-01]\n",
            " [3.52114439e-04]\n",
            " [9.95041132e-01]\n",
            " [9.98827934e-01]\n",
            " [9.99302149e-01]\n",
            " [9.95894015e-01]\n",
            " [2.76863575e-05]\n",
            " [9.78866935e-01]\n",
            " [9.98831391e-01]\n",
            " [3.80960107e-03]\n",
            " [4.29242849e-04]\n",
            " [1.33493543e-03]\n",
            " [5.06636739e-01]\n",
            " [9.59280133e-03]\n",
            " [9.99999285e-01]\n",
            " [8.65642190e-01]\n",
            " [3.21865082e-04]\n",
            " [9.87881780e-01]\n",
            " [4.99847531e-03]\n",
            " [9.99976099e-01]\n",
            " [9.28445697e-01]\n",
            " [9.93207812e-01]\n",
            " [9.97940421e-01]\n",
            " [9.99992251e-01]\n",
            " [9.99966145e-01]\n",
            " [1.25101209e-03]\n",
            " [6.16610050e-04]\n",
            " [9.98224020e-01]\n",
            " [9.99860883e-01]\n",
            " [9.99856830e-01]\n",
            " [1.56432390e-04]\n",
            " [9.88815129e-01]\n",
            " [1.09642744e-04]\n",
            " [9.89892840e-01]\n",
            " [9.95394170e-01]\n",
            " [1.99460983e-03]\n",
            " [9.99983072e-01]\n",
            " [9.99954224e-01]\n",
            " [9.93571162e-01]\n",
            " [9.89462793e-01]\n",
            " [9.85863805e-01]\n",
            " [6.97195530e-04]\n",
            " [9.99975085e-01]\n",
            " [9.85558987e-01]\n",
            " [9.79862630e-01]\n",
            " [9.97596741e-01]\n",
            " [9.99975920e-01]\n",
            " [9.53050554e-01]\n",
            " [9.98457432e-01]\n",
            " [9.97359872e-01]\n",
            " [9.99493241e-01]\n",
            " [9.99895096e-01]\n",
            " [4.57167625e-04]\n",
            " [9.21885908e-01]\n",
            " [9.99870539e-01]\n",
            " [1.14381313e-04]\n",
            " [9.99868274e-01]\n",
            " [4.96476889e-04]\n",
            " [5.55396080e-04]\n",
            " [9.99809861e-01]\n",
            " [4.57173586e-03]\n",
            " [9.98384416e-01]\n",
            " [5.35809994e-03]\n",
            " [4.33585882e-01]\n",
            " [9.99993920e-01]\n",
            " [6.66379929e-05]\n",
            " [9.99752760e-01]\n",
            " [7.78734684e-05]\n",
            " [9.91005957e-01]\n",
            " [9.99665856e-01]\n",
            " [9.91779089e-01]\n",
            " [1.52647495e-04]\n",
            " [9.99986589e-01]\n",
            " [2.93570757e-03]\n",
            " [9.99793470e-01]\n",
            " [9.98344421e-01]\n",
            " [9.99587178e-01]\n",
            " [1.16410553e-02]\n",
            " [9.78406847e-01]\n",
            " [9.52144623e-01]\n",
            " [9.99445975e-01]\n",
            " [9.90324259e-01]\n",
            " [8.57645392e-01]\n",
            " [4.68313694e-03]\n",
            " [9.99859691e-01]\n",
            " [9.38804626e-01]\n",
            " [6.38186932e-04]\n",
            " [9.99825358e-01]\n",
            " [9.98793483e-01]\n",
            " [9.99710560e-01]\n",
            " [1.15557611e-02]\n",
            " [1.71422958e-04]\n",
            " [8.08259845e-03]\n",
            " [9.99413013e-01]\n",
            " [9.95338202e-01]\n",
            " [4.53135371e-03]\n",
            " [9.95565057e-01]\n",
            " [1.29699707e-04]\n",
            " [1.34259254e-01]\n",
            " [7.17393756e-02]\n",
            " [4.58136201e-03]\n",
            " [9.99148130e-01]\n",
            " [9.99994159e-01]\n",
            " [9.95633185e-01]\n",
            " [9.93254662e-01]\n",
            " [9.83721733e-01]\n",
            " [9.99992013e-01]\n",
            " [9.99718726e-01]\n",
            " [9.99998331e-01]\n",
            " [9.99682903e-01]\n",
            " [4.45634127e-03]\n",
            " [1.41918659e-04]\n",
            " [9.93266106e-01]\n",
            " [9.79490459e-01]\n",
            " [9.94513035e-01]\n",
            " [7.20083714e-04]\n",
            " [9.85695720e-01]\n",
            " [9.88604665e-01]\n",
            " [4.63277102e-04]\n",
            " [9.83594418e-01]\n",
            " [9.97006655e-01]\n",
            " [1.07458234e-03]\n",
            " [5.42938709e-04]\n",
            " [9.99978423e-01]\n",
            " [9.99416113e-01]\n",
            " [5.55434346e-01]\n",
            " [9.97051179e-01]\n",
            " [1.14768744e-04]\n",
            " [9.76180434e-01]\n",
            " [9.95610893e-01]\n",
            " [1.92412734e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DRAtv9iMed1L",
        "colab_type": "code",
        "outputId": "3a718345-3a3c-414d-98a7-855cbeac9562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 1. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 1. 0. 1.]\n",
            " [1. 0. 0. ... 1. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}